{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372ae0bb-a2f7-4d71-9cf5-8f9b551cc8e6",
   "metadata": {},
   "source": [
    "# 1. Setup and Configuration\n",
    "- Loads necessary libraries\n",
    "- Defines model hyperparameters and training configurations\n",
    "- Specifies the path to the processed data file from the preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7412543-d1af-4e94-9d50-7320bfd54b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97399db-e0ad-459b-acb7-9c32d387aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_PICKLE_PATH = 'processed_cache_data.pkl'\n",
    "SEQ_LENGTH = 20\n",
    "MODEL_MAX_SEQ_LENGTH = 50\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 5\n",
    "K_PREFETCH_EVAL = 1\n",
    "GRAD_CLIP = 1.0\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "NUM_WORKERS_DATALOADER = 8\n",
    "NUM_INIT_WORKERS_DATASET = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5927a9f0-f38b-41d3-b43e-bf1a08b2142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a5ea3-67b1-496f-86ce-76423806a4d3",
   "metadata": {},
   "source": [
    "# 2. Define Transformer Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fe8a7c-26b4-4e9a-ad74-89b337c879af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84ebaaef-1402-4f75-9a7e-3ce55d2ae8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, attention_mask: torch.Tensor = None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch_size = query.size(0)\n",
    "        seq_len_q = query.size(1)\n",
    "        seq_len_k = key.size(1)\n",
    "        Q = self.W_q(query).view(batch_size, seq_len_q, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.W_k(key).view(batch_size, seq_len_k, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.W_v(value).view(batch_size, seq_len_k, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        if attention_mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(attention_mask == True, float('-inf'))\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        attention_weights = self.dropout_attn(attention_weights)\n",
    "        context_vector = torch.matmul(attention_weights, V).transpose(1, 2).contiguous().view(batch_size, seq_len_q, self.d_model)\n",
    "        output = self.W_o(context_vector)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c9ecf5-fc87-4c2b-bbe7-91966efa8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear2(self.dropout(self.activation(self.linear1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11925f72-919b-409b-907f-dacbcfd952ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlockScratch(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = MultiHeadSelfAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        norm_x = self.norm1(x)\n",
    "        attn_output, _ = self.self_attention(norm_x, norm_x, norm_x, attention_mask)\n",
    "        x = x + self.dropout1(attn_output)\n",
    "        norm_x = self.norm2(x)\n",
    "        ff_output = self.feed_forward(norm_x)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3976fce8-e238-495a-9dfa-663f1b363bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderOnlyTransformerScratch(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int, num_heads: int, num_layers: int, d_ff: int, max_seq_length: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_seq_length)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlockScratch(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout_emb = nn.Dropout(dropout)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc_out.bias.data.zero_()\n",
    "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def _generate_causal_mask(self, size: int, device: torch.device) -> torch.Tensor:\n",
    "        return torch.triu(torch.ones(size, size, device=device, dtype=torch.bool), diagonal=1)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_key_padding_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        batch_size, seq_len = src.shape\n",
    "        device = src.device\n",
    "        emb_out = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        x = self.dropout_emb(self.pos_encoder(emb_out))\n",
    "        causal_mask = self._generate_causal_mask(seq_len, device).unsqueeze(0).unsqueeze(0)\n",
    "        if src_key_padding_mask is not None:\n",
    "            expanded_padding_mask = src_key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "            causal_mask = (causal_mask | expanded_padding_mask).bool()\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, causal_mask)\n",
    "        return self.fc_out(self.final_norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ce5f-d286-4bd5-be05-c62f77ecd1e4",
   "metadata": {},
   "source": [
    "# 3. Define `CacheDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efaba17b-8e82-4b79-a066-7498ff0b4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_single_sequence_pair_for_mp(args_tuple):\n",
    "    # Unpack arguments\n",
    "    indexed_obj_ids_ref, i, sequence_length_val = args_tuple\n",
    "    \n",
    "    # Create the slices. Note: indexed_obj_ids_ref is the full list.\n",
    "    input_seq_list = indexed_obj_ids_ref[i : i + sequence_length_val]\n",
    "    target_seq_list = indexed_obj_ids_ref[i + 1 : i + sequence_length_val + 1]\n",
    "    \n",
    "    return torch.tensor(input_seq_list, dtype=torch.long), \\\n",
    "           torch.tensor(target_seq_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53b042aa-3dd3-4f9d-8c13-a66517760089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheDataset(Dataset):\n",
    "    def __init__(self, filtered_obj_id_sequence: list, list_of_popular_objects: list, sequence_length: int, num_init_workers: int = 0):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.popular_objects_vocab = sorted(list(set(list_of_popular_objects)))\n",
    "        self.obj_to_idx = {obj: i for i, obj in enumerate(self.popular_objects_vocab)}\n",
    "        self.idx_to_obj = {i: obj for obj, i in self.obj_to_idx.items()}\n",
    "        self.vocab_size = len(self.popular_objects_vocab)\n",
    "        \n",
    "        self.indexed_obj_ids = [self.obj_to_idx[obj] for obj in filtered_obj_id_sequence if obj in self.obj_to_idx]\n",
    "        \n",
    "        self.input_sequences = []\n",
    "        self.target_sequences = []\n",
    "        \n",
    "        if len(self.indexed_obj_ids) >= self.sequence_length + 1:\n",
    "            num_total_sequences = len(self.indexed_obj_ids) - self.sequence_length\n",
    "\n",
    "            actual_init_workers = 0\n",
    "            if num_init_workers > 0:\n",
    "                 actual_init_workers = min(num_init_workers, os.cpu_count() if os.cpu_count() else 1)\n",
    "            \n",
    "            min_sequences_for_parallel = 1000 \n",
    "            min_sequences_per_worker = 50\n",
    "\n",
    "            if actual_init_workers > 0 and \\\n",
    "               num_total_sequences >= min_sequences_for_parallel and \\\n",
    "               (num_total_sequences / actual_init_workers) >= min_sequences_per_worker:\n",
    "                \n",
    "                print(f\"Using {actual_init_workers} workers for CacheDataset sequence creation ({num_total_sequences} sequences).\")\n",
    "                tasks_args = [(self.indexed_obj_ids, i, self.sequence_length) for i in range(num_total_sequences)]\n",
    "\n",
    "                # Ensure the pool is only created if multiprocessing is to be used.\n",
    "                # Also, set a proper start method if needed, especially for some OS.\n",
    "                # For Jupyter, 'spawn' or 'forkserver' might be more stable than 'fork' (default on Unix).\n",
    "                # However, let's try with default first.\n",
    "                # ctx = multiprocessing.get_context('spawn') # Example for more control\n",
    "                # with ctx.Pool(processes=actual_init_workers) as pool:\n",
    "                with multiprocessing.Pool(processes=actual_init_workers) as pool:\n",
    "                    results = []\n",
    "                    for pair in tqdm(pool.imap_unordered(_create_single_sequence_pair_for_mp, tasks_args), \n",
    "                                     total=num_total_sequences, \n",
    "                                     desc=\"Creating Dataset Sequences (Parallel)\", \n",
    "                                     unit=\"sequence\", \n",
    "                                     leave=False):\n",
    "                        results.append(pair)\n",
    "                \n",
    "                if results:\n",
    "                    self.input_sequences, self.target_sequences = zip(*results)\n",
    "                    self.input_sequences = list(self.input_sequences)\n",
    "                    self.target_sequences = list(self.target_sequences)\n",
    "            else:\n",
    "                if actual_init_workers > 0:\n",
    "                    print(f\"Dataset size ({num_total_sequences} sequences) or worker load too small for parallel init with {actual_init_workers} workers. Using sequential.\")\n",
    "                for i in tqdm(range(num_total_sequences), desc=\"Creating Dataset Sequences (Sequential)\", unit=\"sequence\", leave=False):\n",
    "                    self.input_sequences.append(torch.tensor(self.indexed_obj_ids[i : i + self.sequence_length], dtype=torch.long))\n",
    "                    self.target_sequences.append(torch.tensor(self.indexed_obj_ids[i + 1 : i + self.sequence_length + 1], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_sequences[idx], self.target_sequences[idx]\n",
    "    \n",
    "    def get_vocab_info(self):\n",
    "        return {'obj_to_idx': self.obj_to_idx, 'idx_to_obj': self.idx_to_obj, 'vocab_size': self.vocab_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4fc02-fb50-439e-9bdf-a5ee03e6a9b3",
   "metadata": {},
   "source": [
    "# 4. Define Training and Evaluation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25ff348-9c8f-4a3f-97b7-7a7939719a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.Module, \n",
    "                optimizer: optim.Optimizer, device: torch.device, grad_clip_value: float = None, epoch_num: int = 0, config_name: str = \"\"):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    # Wrap dataloader with tqdm for batch progress\n",
    "    batch_iterator = tqdm(dataloader, desc=f\"Epoch {epoch_num} Training\", leave=False, unit=\"batch\")\n",
    "    for batch_idx, (input_seqs, target_seqs) in enumerate(batch_iterator):\n",
    "        input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_seqs, src_key_padding_mask=None)\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), target_seqs.view(-1))\n",
    "        loss.backward()\n",
    "        if grad_clip_value:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # Update tqdm description with current loss\n",
    "        batch_iterator.set_postfix_str(f\"Loss: {loss.item():.4f}\")\n",
    "    return total_loss / len(dataloader) if len(dataloader) > 0 else 0.0\n",
    "\n",
    "def evaluate_model(model: nn.Module, dataloader: DataLoader, criterion: nn.Module, \n",
    "                   device: torch.device, k_prefetch: int = 1):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_misses = 0\n",
    "    total_predictions = 0\n",
    "    # Wrap dataloader with tqdm for batch progress\n",
    "    batch_iterator = tqdm(dataloader, desc=\"Evaluating\", leave=False, unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for input_seqs, target_seqs in batch_iterator:\n",
    "            input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)\n",
    "            outputs = model(input_seqs, src_key_padding_mask=None)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), target_seqs.view(-1))\n",
    "            total_loss += loss.item()\n",
    "            actual_k_prefetch = min(k_prefetch, outputs.size(-1))\n",
    "            _, top_k_indices = torch.topk(outputs, k=actual_k_prefetch, dim=2)\n",
    "            target_seqs_expanded = target_seqs.unsqueeze(-1).expand_as(top_k_indices)\n",
    "            hits_at_each_step = torch.any(top_k_indices == target_seqs_expanded, dim=2)\n",
    "            misses_at_each_step = ~hits_at_each_step\n",
    "            total_misses += misses_at_each_step.sum().item()\n",
    "            total_predictions += target_seqs.numel()\n",
    "            # Update tqdm description with current loss\n",
    "            batch_iterator.set_postfix_str(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else 0.0\n",
    "    miss_ratio = total_misses / total_predictions if total_predictions > 0 else 0.0\n",
    "    return avg_loss, miss_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366803d-31cd-4fc4-bd1c-c201844d2e68",
   "metadata": {},
   "source": [
    "# 5. Load Processed Data and Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b531771-8b83-40d4-a856-86cb73937c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data from processed_cache_data.pkl...\n",
      "Loaded filtered sequence of length: 1000\n",
      "Number of unique popular objects for vocabulary: 8\n",
      "Training sequence length: 800\n",
      "Validation sequence length: 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading processed data from {PROCESSED_DATA_PICKLE_PATH}...\")\n",
    "if not os.path.exists(PROCESSED_DATA_PICKLE_PATH):\n",
    "    print(f\"Error: Processed data file not found at {PROCESSED_DATA_PICKLE_PATH}.\")\n",
    "    print(\"Please run the preprocessing notebook first to generate this file.\")\n",
    "    raise FileNotFoundError(f\"Missing {PROCESSED_DATA_PICKLE_PATH}\")\n",
    "\n",
    "with open(PROCESSED_DATA_PICKLE_PATH, 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "filtered_sequence = processed_data['filtered_sequence_popular_obj_ids']\n",
    "list_of_popular_objects_for_vocab = processed_data['list_of_popular_obj_ids']\n",
    "\n",
    "print(f\"Loaded filtered sequence of length: {len(filtered_sequence)}\")\n",
    "print(f\"Number of unique popular objects for vocabulary: {len(list_of_popular_objects_for_vocab)}\")\n",
    "\n",
    "if not filtered_sequence or not list_of_popular_objects_for_vocab:\n",
    "    print(\"Error: Loaded data is empty. Cannot proceed with training.\")\n",
    "    raise ValueError(\"Empty data loaded from pickle file.\")\n",
    "\n",
    "# Split the filtered sequence for training and validation\n",
    "split_idx = int(TRAIN_SPLIT_RATIO * len(filtered_sequence))\n",
    "train_filtered_ids = filtered_sequence[:split_idx]\n",
    "val_filtered_ids = filtered_sequence[split_idx:]\n",
    "\n",
    "print(f\"Training sequence length: {len(train_filtered_ids)}\")\n",
    "print(f\"Validation sequence length: {len(val_filtered_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98d273d8-a8aa-400c-8c01-0a4477128003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Training Dataset...\n",
      "Dataset size (780 sequences) or worker load too small for parallel init with 8 workers. Using sequential.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3948e0af8318445a927cf466833c1594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Dataset Sequences (Sequential):   0%|          | 0/780 [00:00<?, ?sequence/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Validation Dataset...\n",
      "Dataset size (180 sequences) or worker load too small for parallel init with 8 workers. Using sequential.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014e231490344f6ead5a5fcd12692bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Dataset Sequences (Sequential):   0%|          | 0/180 [00:00<?, ?sequence/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Datasets and DataLoaders\n",
    "# The vocabulary is defined by list_of_popular_objects_for_vocab for both datasets.\n",
    "print(\"Creating Training Dataset...\")\n",
    "train_dataset = CacheDataset(train_filtered_ids, list_of_popular_objects_for_vocab, SEQ_LENGTH, num_init_workers=NUM_INIT_WORKERS_DATASET)\n",
    "print(\"Creating Validation Dataset...\")\n",
    "val_dataset = CacheDataset(val_filtered_ids, list_of_popular_objects_for_vocab, SEQ_LENGTH, num_init_workers=NUM_INIT_WORKERS_DATASET)\n",
    "\n",
    "# Ensure datasets are not empty\n",
    "if len(train_dataset) == 0:\n",
    "    raise ValueError(\"Training dataset is empty after processing. Insufficient data for SEQ_LENGTH.\")\n",
    "if len(val_dataset) == 0:\n",
    "    print(\"Warning: Validation dataset is empty. Evaluation will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59ee97cd-8f69-40a7-b336-a9ae0625057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory_flag = True if device.type == 'cuda' else False\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=NUM_WORKERS_DATALOADER, pin_memory=pin_memory_flag)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS_DATALOADER, pin_memory=pin_memory_flag) if len(val_dataset) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4827c86-971c-4926-8181-8dc03b4bb104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective Vocabulary size for all models: 8\n",
      "Number of training sequences: 780\n",
      "Number of validation sequences: 180\n"
     ]
    }
   ],
   "source": [
    "MODEL_VOCAB_SIZE = train_dataset.vocab_size\n",
    "print(f\"Effective Vocabulary size for all models: {MODEL_VOCAB_SIZE}\")\n",
    "print(f\"Number of training sequences: {len(train_dataset)}\")\n",
    "print(f\"Number of validation sequences: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca48cb-8824-4cad-85ac-c9d51f77d1de",
   "metadata": {},
   "source": [
    "# 6. Define Hyperparameter Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4623ebac-ca76-4838-85e0-584b0e4889c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_configs = [\n",
    "    {\n",
    "        \"name\": \"Config1_Baseline\",\n",
    "        \"D_MODEL\": 128,\n",
    "        \"NUM_HEADS\": 4,\n",
    "        \"NUM_LAYERS\": 3,\n",
    "        \"D_FF\": 256,\n",
    "        \"DROPOUT\": 0.1,\n",
    "        \"LEARNING_RATE\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config2_LargerModel_LowerLR\",\n",
    "        \"D_MODEL\": 256, # Larger model\n",
    "        \"NUM_HEADS\": 8,  # Must be divisor of D_MODEL\n",
    "        \"NUM_LAYERS\": 4, # Deeper model\n",
    "        \"D_FF\": 512,   # Larger FFN\n",
    "        \"DROPOUT\": 0.15, # Slightly more dropout for larger model\n",
    "        \"LEARNING_RATE\": 0.0005, # Lower LR for potentially more stable training\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config3_SmallerModel_HigherLR_MoreDropout\",\n",
    "        \"D_MODEL\": 64,  # Smaller model\n",
    "        \"NUM_HEADS\": 2,  # Must be divisor of D_MODEL\n",
    "        \"NUM_LAYERS\": 2, # Shallower model\n",
    "        \"D_FF\": 128,   # Smaller FFN\n",
    "        \"DROPOUT\": 0.2,  # Higher dropout\n",
    "        \"LEARNING_RATE\": 0.002, # Higher LR\n",
    "    },\n",
    "    # Add a fourth configuration\n",
    "    {\n",
    "        \"name\": \"Config4_MediumModel_VariedHeads\",\n",
    "        \"D_MODEL\": 128,\n",
    "        \"NUM_HEADS\": 8,  # More heads for same D_MODEL\n",
    "        \"NUM_LAYERS\": 3,\n",
    "        \"D_FF\": 256,\n",
    "        \"DROPOUT\": 0.1,\n",
    "        \"LEARNING_RATE\": 0.001,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598b3ad-439a-4dcc-9bd3-be1343661da7",
   "metadata": {},
   "source": [
    "# 7. Training and Evaluation Loop for Each Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e8293db-6339-4732-be67-87dcb8b6f641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb03584884d140e58d8e903ed2693806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Configurations:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================== Starting Training for: Config1_Baseline ====================\n",
      "Hyperparameters: {'name': 'Config1_Baseline', 'D_MODEL': 128, 'NUM_HEADS': 4, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "Model for Config1_Baseline initialized with 399752 parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d6789a2577437fa519167bc929845f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config1_Baseline' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b086701760014637864210b7736f5b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 1 Training: Avg Loss: 0.2957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71681d27004e4e83a47a2dfe6620885d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 1 Validation: Avg Loss: 0.1984, Miss Ratio (Top-1): 0.0317\n",
      "Config: Config1_Baseline, Epoch 1 duration: 5.44 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ca33b0e5994d178f930349b09fffeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 2 Training: Avg Loss: 0.2558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c84ded198344351957a5c425b89a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 2 Validation: Avg Loss: 0.2381, Miss Ratio (Top-1): 0.0692\n",
      "Config: Config1_Baseline, Epoch 2 duration: 5.06 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281d9c35f02d4369b49bb7199327ff93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 3 Training: Avg Loss: 0.2492\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4fd78c34f84a85a5d8bf3f79efd932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 3 Validation: Avg Loss: 0.3340, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config1_Baseline, Epoch 3 duration: 5.03 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2291af08dcf74d8dbea656b8372d221d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 4 Training: Avg Loss: 0.2478\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07fb6ae68ce4743a4efe851e71f0680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 4 Validation: Avg Loss: 0.3996, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config1_Baseline, Epoch 4 duration: 5.01 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c562b063e7344311b0d5c40f79aa5425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 5 Training: Avg Loss: 0.2451\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba5d798ff9c406f8958590bda2a72c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_Baseline, Epoch 5 Validation: Avg Loss: 0.3303, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config1_Baseline, Epoch 5 duration: 4.83 seconds\n",
      "\n",
      "Training for Config1_Baseline completed in 25.43 seconds.\n",
      "Best Validation Miss Ratio for Config1_Baseline: 0.0317 at Epoch 1\n",
      "\n",
      "\n",
      "==================== Starting Training for: Config2_LargerModel_LowerLR ====================\n",
      "Hyperparameters: {'name': 'Config2_LargerModel_LowerLR', 'D_MODEL': 256, 'NUM_HEADS': 8, 'NUM_LAYERS': 4, 'D_FF': 512, 'DROPOUT': 0.15, 'LEARNING_RATE': 0.0005}\n",
      "Model for Config2_LargerModel_LowerLR initialized with 2113032 parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2b281c3a404f7a9dcab8feb98fd214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config2_LargerModel_LowerLR' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c79ed5e2d9040adbaec2b13f0d7a4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 1 Training: Avg Loss: 0.3064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f200063986048ce9ae4f6b0fdcc654a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 1 Validation: Avg Loss: 0.2132, Miss Ratio (Top-1): 0.0317\n",
      "Config: Config2_LargerModel_LowerLR, Epoch 1 duration: 5.65 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c267d78b4849b4a34fc5727f241ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 2 Training: Avg Loss: 0.2559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abf16bd92dd40099f76382fd19dc8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 2 Validation: Avg Loss: 0.2939, Miss Ratio (Top-1): 0.0764\n",
      "Config: Config2_LargerModel_LowerLR, Epoch 2 duration: 5.63 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42edb9ec779c45b8a1ad99e63a0b0194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 3 Training: Avg Loss: 0.2528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f8a124d6e149adbfeef3d20a494eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 3 Validation: Avg Loss: 0.3438, Miss Ratio (Top-1): 0.0764\n",
      "Config: Config2_LargerModel_LowerLR, Epoch 3 duration: 5.64 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bca6ec346f846c1a62431091e47e16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 4 Training: Avg Loss: 0.2488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645695ecc8ad427e8659ea134aacb9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 4 Validation: Avg Loss: 0.3395, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config2_LargerModel_LowerLR, Epoch 4 duration: 5.66 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cf26d0bcbc49d39385da29df896993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 5 Training: Avg Loss: 0.2463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff91773921c4b2f91a6016dc28202c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_LargerModel_LowerLR, Epoch 5 Validation: Avg Loss: 0.4580, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config2_LargerModel_LowerLR, Epoch 5 duration: 5.65 seconds\n",
      "\n",
      "Training for Config2_LargerModel_LowerLR completed in 28.33 seconds.\n",
      "Best Validation Miss Ratio for Config2_LargerModel_LowerLR: 0.0317 at Epoch 1\n",
      "\n",
      "\n",
      "==================== Starting Training for: Config3_SmallerModel_HigherLR_MoreDropout ====================\n",
      "Hyperparameters: {'name': 'Config3_SmallerModel_HigherLR_MoreDropout', 'D_MODEL': 64, 'NUM_HEADS': 2, 'NUM_LAYERS': 2, 'D_FF': 128, 'DROPOUT': 0.2, 'LEARNING_RATE': 0.002}\n",
      "Model for Config3_SmallerModel_HigherLR_MoreDropout initialized with 68104 parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e157ad53861842fbb0a882e7025789a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config3_SmallerModel_HigherLR_MoreDropout' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dddc22ab004e25b932fae487bad800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 1 Training: Avg Loss: 0.3122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5b2c142c154c94aa1d4483110df156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 1 Validation: Avg Loss: 0.2017, Miss Ratio (Top-1): 0.0311\n",
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 1 duration: 4.16 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e494ad2ac434d7aa5727185d58a647c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 2 Training: Avg Loss: 0.2704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59e3db8aeec466db226ea4aff42a7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 2 Validation: Avg Loss: 0.1928, Miss Ratio (Top-1): 0.0311\n",
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 2 duration: 4.22 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa7abf37efe4cf793ce9441ae2b7054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 3 Training: Avg Loss: 0.2652\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8470319bcf9e47778e4ce73b2537bff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 3 Validation: Avg Loss: 0.2053, Miss Ratio (Top-1): 0.0311\n",
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 3 duration: 4.16 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674621741de6468e951251b68a0383f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 4 Training: Avg Loss: 0.2585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079361db51c24be29f7d5926085f37c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 4 Validation: Avg Loss: 0.3369, Miss Ratio (Top-1): 0.0764\n",
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 4 duration: 4.22 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d26d70f95d4e9995d9c54f6c7f1f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 5 Training: Avg Loss: 0.2581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84278c04b9240cdaad5d470b524f948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 5 Validation: Avg Loss: 0.3415, Miss Ratio (Top-1): 0.0764\n",
      "Config: Config3_SmallerModel_HigherLR_MoreDropout, Epoch 5 duration: 4.21 seconds\n",
      "\n",
      "Training for Config3_SmallerModel_HigherLR_MoreDropout completed in 21.01 seconds.\n",
      "Best Validation Miss Ratio for Config3_SmallerModel_HigherLR_MoreDropout: 0.0311 at Epoch 1\n",
      "\n",
      "\n",
      "==================== Starting Training for: Config4_MediumModel_VariedHeads ====================\n",
      "Hyperparameters: {'name': 'Config4_MediumModel_VariedHeads', 'D_MODEL': 128, 'NUM_HEADS': 8, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "Model for Config4_MediumModel_VariedHeads initialized with 399752 parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c811312a87491bbf9114d75d59761f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config4_MediumModel_VariedHeads' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c84d2e9003a45b7b01cfd070f44dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 1 Training: Avg Loss: 0.2909\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aef427b675a4904b0c6555c73959f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 1 Validation: Avg Loss: 0.1936, Miss Ratio (Top-1): 0.0311\n",
      "Config: Config4_MediumModel_VariedHeads, Epoch 1 duration: 4.96 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e951679360f42dab2ad6fa8f9e0b3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 2 Training: Avg Loss: 0.2586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574aa3e6a545457c8e82c14a2b39c6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 2 Validation: Avg Loss: 0.2278, Miss Ratio (Top-1): 0.0400\n",
      "Config: Config4_MediumModel_VariedHeads, Epoch 2 duration: 5.06 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079692cb03db4a83beeb454a1094e4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 3 Training: Avg Loss: 0.2522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1558727ab61344e99a8030e7818a584c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 3 Validation: Avg Loss: 0.2827, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config4_MediumModel_VariedHeads, Epoch 3 duration: 4.95 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7992d451b1f4f52b95d9ed79ef74076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 4 Training: Avg Loss: 0.2487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f996154b6344064a1f1955f6998f4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 4 Validation: Avg Loss: 0.3521, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config4_MediumModel_VariedHeads, Epoch 4 duration: 5.09 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4dbe1e2b2c4e5f9d047e505c81fad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/97 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 5 Training: Avg Loss: 0.2460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb19a1c35084c4587f6fce2904b31f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/23 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MediumModel_VariedHeads, Epoch 5 Validation: Avg Loss: 0.4430, Miss Ratio (Top-1): 0.0761\n",
      "Config: Config4_MediumModel_VariedHeads, Epoch 5 duration: 4.71 seconds\n",
      "\n",
      "Training for Config4_MediumModel_VariedHeads completed in 24.82 seconds.\n",
      "Best Validation Miss Ratio for Config4_MediumModel_VariedHeads: 0.0311 at Epoch 1\n",
      "\n",
      "\n",
      "==================== All Configurations Processed ====================\n"
     ]
    }
   ],
   "source": [
    "all_results = [] \n",
    "\n",
    "# Outer loop for configurations with tqdm - assign the instance to a variable\n",
    "configurations_pbar = tqdm(hyperparameter_configs, desc=\"Configurations\")\n",
    "for config in configurations_pbar: # Iterate over the tqdm instance\n",
    "    print(f\"\\n\\n{'='*20} Starting Training for: {config['name']} {'='*20}\")\n",
    "    print(f\"Hyperparameters: {config}\")\n",
    "    start_time_config = time.time()\n",
    "\n",
    "    current_model = DecoderOnlyTransformerScratch(\n",
    "        vocab_size=MODEL_VOCAB_SIZE,\n",
    "        d_model=config['D_MODEL'],\n",
    "        num_heads=config['NUM_HEADS'],\n",
    "        num_layers=config['NUM_LAYERS'],\n",
    "        d_ff=config['D_FF'],\n",
    "        max_seq_length=MODEL_MAX_SEQ_LENGTH,\n",
    "        dropout=config['DROPOUT']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(current_model.parameters(), lr=config['LEARNING_RATE'])\n",
    "\n",
    "    print(f\"Model for {config['name']} initialized with {sum(p.numel() for p in current_model.parameters())} parameters.\")\n",
    "\n",
    "    config_results = {\n",
    "        \"config_name\": config['name'],\n",
    "        \"hyperparameters\": config,\n",
    "        \"train_losses\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_miss_ratios\": [],\n",
    "        \"best_val_miss_ratio\": float('inf'),\n",
    "        \"best_epoch\": -1\n",
    "    }\n",
    "\n",
    "    if len(train_dataloader) == 0:\n",
    "        print(f\"Training dataloader is empty for {config['name']}. Skipping training for this config.\")\n",
    "        all_results.append(config_results) \n",
    "        continue\n",
    "\n",
    "    for epoch in tqdm(range(1, NUM_EPOCHS + 1), desc=f\"Config '{config['name']}' Epochs\", leave=False):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        avg_train_loss = train_epoch(current_model, train_dataloader, criterion, optimizer, device, GRAD_CLIP, epoch_num=epoch, config_name=config['name'])\n",
    "        config_results[\"train_losses\"].append(avg_train_loss)\n",
    "        print(f\"Config: {config['name']}, Epoch {epoch} Training: Avg Loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        current_val_loss = float('nan')\n",
    "        current_val_miss_ratio = float('nan')\n",
    "\n",
    "        if val_dataloader and len(val_dataset) > 0:\n",
    "            avg_val_loss, val_miss_ratio = evaluate_model(current_model, val_dataloader, criterion, device, k_prefetch=K_PREFETCH_EVAL)\n",
    "            config_results[\"val_losses\"].append(avg_val_loss)\n",
    "            config_results[\"val_miss_ratios\"].append(val_miss_ratio)\n",
    "            current_val_loss = avg_val_loss\n",
    "            current_val_miss_ratio = val_miss_ratio\n",
    "            print(f\"Config: {config['name']}, Epoch {epoch} Validation: Avg Loss: {avg_val_loss:.4f}, Miss Ratio (Top-{K_PREFETCH_EVAL}): {val_miss_ratio:.4f}\")\n",
    "            \n",
    "            if not math.isnan(val_miss_ratio) and val_miss_ratio < config_results[\"best_val_miss_ratio\"]:\n",
    "                config_results[\"best_val_miss_ratio\"] = val_miss_ratio\n",
    "                config_results[\"best_epoch\"] = epoch\n",
    "        else:\n",
    "            config_results[\"val_losses\"].append(float('nan')) \n",
    "            config_results[\"val_miss_ratios\"].append(float('nan'))\n",
    "            if len(val_dataset) == 0:\n",
    "                 print(f\"Config: {config['name']}, Epoch {epoch}: Validation dataset is empty. Skipping validation.\")\n",
    "            else:\n",
    "                 print(f\"Config: {config['name']}, Epoch {epoch}: Validation dataloader not available. Skipping validation.\")\n",
    "        \n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        # Update outer tqdm (config progress bar) with validation miss ratio if available\n",
    "        if not math.isnan(current_val_miss_ratio):\n",
    "             # Call set_description_str on the instance of the outer progress bar\n",
    "             configurations_pbar.set_description_str(f\"Configurations (Best Miss for {config['name']}: {config_results['best_val_miss_ratio']:.4f})\")\n",
    "        print(f\"Config: {config['name']}, Epoch {epoch} duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "    config_duration = time.time() - start_time_config\n",
    "    print(f\"\\nTraining for {config['name']} completed in {config_duration:.2f} seconds.\")\n",
    "    print(f\"Best Validation Miss Ratio for {config['name']}: {config_results['best_val_miss_ratio']:.4f} at Epoch {config_results['best_epoch']}\")\n",
    "    all_results.append(config_results)\n",
    "    configurations_pbar.set_description_str(\"Configurations\") # Reset description for next config\n",
    "\n",
    "print(f\"\\n\\n{'='*20} All Configurations Processed {'='*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4114f2f-c5d2-43bc-81e9-78a0e2ae8453",
   "metadata": {},
   "source": [
    "# 8. Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1902af19-b265-4d36-948a-02c917528ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Summary of All Hyperparameter Configurations ---\n",
      "\n",
      "Configuration: Config1_Baseline\n",
      "  Hyperparameters: {'name': 'Config1_Baseline', 'D_MODEL': 128, 'NUM_HEADS': 4, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "  Final Training Loss (Epoch 5): 0.2451\n",
      "  Final Validation Loss (Epoch 5): 0.3303\n",
      "  Final Validation Miss Ratio (Epoch 5): 0.0761\n",
      "  Best Validation Miss Ratio: 0.0317 (Epoch 1)\n",
      "\n",
      "Configuration: Config2_LargerModel_LowerLR\n",
      "  Hyperparameters: {'name': 'Config2_LargerModel_LowerLR', 'D_MODEL': 256, 'NUM_HEADS': 8, 'NUM_LAYERS': 4, 'D_FF': 512, 'DROPOUT': 0.15, 'LEARNING_RATE': 0.0005}\n",
      "  Final Training Loss (Epoch 5): 0.2463\n",
      "  Final Validation Loss (Epoch 5): 0.4580\n",
      "  Final Validation Miss Ratio (Epoch 5): 0.0761\n",
      "  Best Validation Miss Ratio: 0.0317 (Epoch 1)\n",
      "\n",
      "Configuration: Config3_SmallerModel_HigherLR_MoreDropout\n",
      "  Hyperparameters: {'name': 'Config3_SmallerModel_HigherLR_MoreDropout', 'D_MODEL': 64, 'NUM_HEADS': 2, 'NUM_LAYERS': 2, 'D_FF': 128, 'DROPOUT': 0.2, 'LEARNING_RATE': 0.002}\n",
      "  Final Training Loss (Epoch 5): 0.2581\n",
      "  Final Validation Loss (Epoch 5): 0.3415\n",
      "  Final Validation Miss Ratio (Epoch 5): 0.0764\n",
      "  Best Validation Miss Ratio: 0.0311 (Epoch 1)\n",
      "\n",
      "Configuration: Config4_MediumModel_VariedHeads\n",
      "  Hyperparameters: {'name': 'Config4_MediumModel_VariedHeads', 'D_MODEL': 128, 'NUM_HEADS': 8, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "  Final Training Loss (Epoch 5): 0.2460\n",
      "  Final Validation Loss (Epoch 5): 0.4430\n",
      "  Final Validation Miss Ratio (Epoch 5): 0.0761\n",
      "  Best Validation Miss Ratio: 0.0311 (Epoch 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- Summary of All Hyperparameter Configurations ---\")\n",
    "for result in all_results:\n",
    "    print(f\"\\nConfiguration: {result['config_name']}\")\n",
    "    print(f\"  Hyperparameters: {result['hyperparameters']}\")\n",
    "    if result['train_losses']: # Check if training was run\n",
    "        print(f\"  Final Training Loss (Epoch {len(result['train_losses'])}): {result['train_losses'][-1]:.4f}\")\n",
    "        if result['val_miss_ratios'] and not math.isnan(result['val_miss_ratios'][-1]):\n",
    "             print(f\"  Final Validation Loss (Epoch {len(result['val_losses'])}): {result['val_losses'][-1]:.4f}\")\n",
    "             print(f\"  Final Validation Miss Ratio (Epoch {len(result['val_miss_ratios'])}): {result['val_miss_ratios'][-1]:.4f}\")\n",
    "        print(f\"  Best Validation Miss Ratio: {result['best_val_miss_ratio']:.4f} (Epoch {result['best_epoch']})\")\n",
    "    else:\n",
    "        print(\"  Training was not run for this configuration (e.g., empty dataloader).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09b8e4f7-b25d-4f5b-b461-680b94e7ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Overall Best Configuration ---\n",
      "Name: Config3_SmallerModel_HigherLR_MoreDropout\n",
      "Best Validation Miss Ratio: 0.0311 at Epoch 1\n",
      "Hyperparameters: {'name': 'Config3_SmallerModel_HigherLR_MoreDropout', 'D_MODEL': 64, 'NUM_HEADS': 2, 'NUM_LAYERS': 2, 'D_FF': 128, 'DROPOUT': 0.2, 'LEARNING_RATE': 0.002}\n"
     ]
    }
   ],
   "source": [
    "# Find the overall best configuration based on best_val_miss_ratio\n",
    "best_overall_config_result = None\n",
    "if all_results:\n",
    "    # Filter out results where training might not have run or validation was skipped leading to inf miss ratio\n",
    "    valid_results = [r for r in all_results if r['best_val_miss_ratio'] != float('inf') and r['best_val_miss_ratio'] is not None and not math.isnan(r['best_val_miss_ratio'])]\n",
    "    if valid_results:\n",
    "        best_overall_config_result = min(valid_results, key=lambda x: x['best_val_miss_ratio'])\n",
    "\n",
    "if best_overall_config_result:\n",
    "    print(f\"\\n--- Overall Best Configuration ---\")\n",
    "    print(f\"Name: {best_overall_config_result['config_name']}\")\n",
    "    print(f\"Best Validation Miss Ratio: {best_overall_config_result['best_val_miss_ratio']:.4f} at Epoch {best_overall_config_result['best_epoch']}\")\n",
    "    print(f\"Hyperparameters: {best_overall_config_result['hyperparameters']}\")\n",
    "else:\n",
    "    print(\"\\nCould not determine an overall best configuration (e.g., no valid validation results).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
