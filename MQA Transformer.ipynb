{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372ae0bb-a2f7-4d71-9cf5-8f9b551cc8e6",
   "metadata": {},
   "source": [
    "# 1. Setup and Configuration\n",
    "- Loads necessary libraries\n",
    "- Defines model hyperparameters and training configurations\n",
    "- Specifies the path to the processed data file from the preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7412543-d1af-4e94-9d50-7320bfd54b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from collections import Counter, deque \n",
    "from tqdm.notebook import tqdm \n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97399db-e0ad-459b-acb7-9c32d387aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_PICKLE_PATH = 'processed_cache_data.pkl' \n",
    "SEQ_LENGTH = 20      \n",
    "MODEL_MAX_SEQ_LENGTH = 50\n",
    "BATCH_SIZE = 8             \n",
    "NUM_EPOCHS = 5 \n",
    "K_PREFETCH_MODEL = 1\n",
    "LRU_CACHE_SIZE_PERCENTAGE = 0.001 \n",
    "GRAD_CLIP = 1.0\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "NUM_WORKERS_DATALOADER = 8\n",
    "NUM_INIT_WORKERS_DATASET = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5927a9f0-f38b-41d3-b43e-bf1a08b2142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a5ea3-67b1-496f-86ce-76423806a4d3",
   "metadata": {},
   "source": [
    "# 2. Define Transformer Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fe8a7c-26b4-4e9a-ad74-89b337c879af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Kelas ini mengimplementasikan mekanisme positional encoding dari transformer\n",
    "Mekanisme ini akan menambahkan informasi mengenai posisi dari token pada sequence masukan\n",
    "Mekanisme ini penting karena transformer memroses token secara parallel sehingga perlu diketahui konteks posisi dari token\n",
    "'''\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "\n",
    "        # Ditambahkan dropout untuk mencegah overfitting\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Tensor ini akan merepresentasikan posisi token\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "\n",
    "        # Menghitung pembagi dari fungsi sinus dan cosinus yang akan digunakan pada positional encoding\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Inisialisasi tensor positional encoding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        # Nilai dari positional encoding untuk elemen berindeks ganjil adalah cosinus dan genap adalah sinus\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Memasukkan positional encoding sebagai buffer --> buffer adalah state dari model yang tidak dilatih\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Menghitung nilai positional encoding dengan menambahkan nilai positional encoding ke tensor masukan\n",
    "        # Setelah itu aplikasikan dropout\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ebaaef-1402-4f75-9a7e-3ce55d2ae8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Kelas ini mengimplementasikan multi-query self-attention (MQSA)\n",
    "MQSA merupakan optimasi dari Multi-Head Self-Attention (MHSA)\n",
    "MQSA tetap memiliki multiple query heads akan tetapi hanya menggunakan satu projeksi Key dan Value pada seluruh Query head\n",
    "Optimasi MQSA ini menyebabkan berkurangnya jumlah parameter yang dibutuhkan\n",
    "'''\n",
    "class MultiQuerySelfAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_query_heads: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Inisialisasi jumlah attention head dan dimensinya\n",
    "        assert d_model % num_query_heads == 0, \"d_model must be divisible by num_query_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.num_query_heads = num_query_heads\n",
    "        self.query_head_dim = d_model // num_query_heads # Dimension of each query head\n",
    "\n",
    "        # Dimensi dari projeksi Key dan Value pada implementasi ini akan sama dengan dimensi dari Query head\n",
    "        self.kv_dim = self.query_head_dim \n",
    "\n",
    "        # Inisialisasi linear layer proyeksi Query, Key, dan Value\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, self.kv_dim)\n",
    "        self.W_v = nn.Linear(d_model, self.kv_dim)\n",
    "\n",
    "        # Inisialisasi linear layer yang akan menjadi output dari Q, K, dan V\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output projection\n",
    "\n",
    "        # Digunakan juga dropout untuk mencegah overfitting\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query_input: torch.Tensor, key_input: torch.Tensor, value_input: torch.Tensor, attention_mask: torch.Tensor = None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch_size = query_input.size(0)\n",
    "        seq_len_q = query_input.size(1)\n",
    "        seq_len_k = key_input.size(1)\n",
    "        seq_len_v = value_input.size(1)\n",
    "\n",
    "        # Dilakukan proyeksi Query untuk setiap attention head\n",
    "        Q = self.W_q(query_input)\n",
    "        Q = Q.view(batch_size, seq_len_q, self.num_query_heads, self.query_head_dim).transpose(1, 2)\n",
    "\n",
    "        # Dilakukan proyeksi Key dan Value pada shared projection\n",
    "        K_shared = self.W_k(key_input)    # (B, L_k, D_kv)\n",
    "        V_shared = self.W_v(value_input)  # (B, L_v, D_kv)\n",
    "\n",
    "        # Dilakukan pemrosesan supaya shared Key dan Value dapat dibroadcast ke setiap head\n",
    "        K_shared = K_shared.unsqueeze(1) # (B, 1, L_k, D_kv)\n",
    "        V_shared = V_shared.unsqueeze(1) # (B, 1, L_v, D_kv)\n",
    "        \n",
    "        # Dihitung nilai atensi (kemiripan query ke key) menggunakan scaled dot-product attention\n",
    "        attention_scores = torch.matmul(Q, K_shared.transpose(-2, -1)) / math.sqrt(self.query_head_dim)\n",
    "\n",
    "        # Apabila ada masking, maka diterapkan\n",
    "        # Masking ini digunakan untuk mencegah decoder dari melihat token di depan (future token)\n",
    "        if attention_mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(attention_mask == True, float('-inf'))\n",
    "            \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1) # (B, H_q, L_q, L_k)\n",
    "        attention_weights = self.dropout_attn(attention_weights)\n",
    "        \n",
    "        # Hitung context vector\n",
    "        # Hasil vector ini adalah weighted average dari Values\n",
    "        context_vector = torch.matmul(attention_weights, V_shared)\n",
    "        context_vector = context_vector.transpose(1, 2).contiguous().view(batch_size, seq_len_q, self.d_model) # D_model = H_q * D_kv (if D_kv=D_qh)\n",
    "        output = self.W_o(context_vector) \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c9ecf5-fc87-4c2b-bbe7-91966efa8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implementasi dari mekanisme position wise feed forward\n",
    "Mekanisme / lapisan ini berada tepat setelah MHSA\n",
    "Lapisan ini digunakan untuk menambahkan atau membuat fitur menjadi non-linear\n",
    "'''\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear2(self.dropout(self.activation(self.linear1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11925f72-919b-409b-907f-dacbcfd952ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Kelas yang merepresentasikan satu blok decoder pada transformer\n",
    "Kelas ini menggabungkan MHQA dan Position-Wise Feed-Forward\n",
    "'''\n",
    "class DecoderBlockScratch(nn.Module):\n",
    "    def __init__(self, d_model: int, num_query_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = MultiQuerySelfAttention(d_model, num_query_heads, dropout) \n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        norm_x = self.norm1(x)\n",
    "        attn_output, _ = self.self_attention(norm_x, norm_x, norm_x, attention_mask)\n",
    "        x = x + self.dropout1(attn_output)\n",
    "        norm_x = self.norm2(x)\n",
    "        ff_output = self.feed_forward(norm_x)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3976fce8-e238-495a-9dfa-663f1b363bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Kelas yang merepresentasikan decoder yang telah di-assembly menjadi transformer\n",
    "Transformer ini melakukan embedding dengan mengubah token menjadi dense vector\n",
    "'''\n",
    "class DecoderOnlyTransformerScratch(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int, num_query_heads: int, num_layers: int, # num_heads -> num_query_heads\n",
    "                 d_ff: int, max_seq_length: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_seq_length)\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            DecoderBlockScratch(d_model, num_query_heads, d_ff, dropout) for _ in range(num_layers)]) # Pass num_query_heads\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout_emb = nn.Dropout(dropout)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc_out.bias.data.zero_()\n",
    "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def _generate_causal_mask(self, size: int, device: torch.device) -> torch.Tensor:\n",
    "        # (Unchanged)\n",
    "        return torch.triu(torch.ones(size, size, device=device, dtype=torch.bool), diagonal=1)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_key_padding_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        batch_size, seq_len = src.shape\n",
    "        device = src.device\n",
    "        if seq_len > self.max_seq_length:\n",
    "            pass \n",
    "        emb_out = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        x = self.dropout_emb(self.pos_encoder(emb_out))\n",
    "        \n",
    "        causal_mask_base = self._generate_causal_mask(seq_len, device) \n",
    "        combined_attention_mask = causal_mask_base.unsqueeze(0).unsqueeze(0) \n",
    "\n",
    "        if src_key_padding_mask is not None:\n",
    "            expanded_padding_mask = src_key_padding_mask.unsqueeze(1).unsqueeze(2) \n",
    "            combined_attention_mask = combined_attention_mask | expanded_padding_mask\n",
    "            combined_attention_mask = combined_attention_mask.bool() \n",
    "\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, combined_attention_mask)\n",
    "            \n",
    "        x = self.final_norm(x)\n",
    "        logits = self.fc_out(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ce5f-d286-4bd5-be05-c62f77ecd1e4",
   "metadata": {},
   "source": [
    "# 3. Define `CacheDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efaba17b-8e82-4b79-a066-7498ff0b4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fungsi ini digunakan untuk menciptakan slices dari sequence\n",
    "Slices yang dihasilkan menggunakan prinsip sliding window\n",
    "'''\n",
    "def _create_single_sequence_pair_for_mp(args_tuple):\n",
    "    indexed_obj_ids_ref, i, sequence_length_val = args_tuple\n",
    "    \n",
    "    input_seq_list = indexed_obj_ids_ref[i : i + sequence_length_val]\n",
    "    target_seq_list = indexed_obj_ids_ref[i + 1 : i + sequence_length_val + 1]\n",
    "    \n",
    "    return torch.tensor(input_seq_list, dtype=torch.long), \\\n",
    "           torch.tensor(target_seq_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53b042aa-3dd3-4f9d-8c13-a66517760089",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Kelas dataset dari sekuens akses objek\n",
    "Kelas ini akan merubah sekuens masukan menjadi potongan sekuens berbasis sliding window\n",
    "'''\n",
    "class CacheDataset(Dataset):\n",
    "    def __init__(self, filtered_obj_id_sequence: list, list_of_popular_objects: list, sequence_length: int, num_init_workers: int = 0):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.popular_objects_vocab = sorted(list(set(list_of_popular_objects)))\n",
    "        self.obj_to_idx = {obj: i for i, obj in enumerate(self.popular_objects_vocab)}\n",
    "        self.idx_to_obj = {i: obj for obj, i in self.obj_to_idx.items()}\n",
    "        self.vocab_size = len(self.popular_objects_vocab)\n",
    "        \n",
    "        self.indexed_obj_ids = [self.obj_to_idx[obj] for obj in filtered_obj_id_sequence if obj in self.obj_to_idx]\n",
    "        \n",
    "        self.input_sequences = []\n",
    "        self.target_sequences = []\n",
    "        \n",
    "        if len(self.indexed_obj_ids) >= self.sequence_length + 1:\n",
    "            num_total_sequences = len(self.indexed_obj_ids) - self.sequence_length\n",
    "\n",
    "            actual_init_workers = 0\n",
    "            if num_init_workers > 0:\n",
    "                 actual_init_workers = min(num_init_workers, os.cpu_count() if os.cpu_count() else 1) \n",
    "            \n",
    "            min_sequences_for_parallel = 1000 \n",
    "            min_sequences_per_worker = 50 \n",
    "\n",
    "            if actual_init_workers > 0 and \\\n",
    "               num_total_sequences >= min_sequences_for_parallel and \\\n",
    "               (num_total_sequences / actual_init_workers) >= min_sequences_per_worker:\n",
    "                \n",
    "                print(f\"Using {actual_init_workers} workers for CacheDataset sequence creation ({num_total_sequences} sequences).\")\n",
    "                tasks_args = [(self.indexed_obj_ids, i, self.sequence_length) for i in range(num_total_sequences)]\n",
    "                \n",
    "                with multiprocessing.Pool(processes=actual_init_workers) as pool:\n",
    "                    results_list_pairs = []\n",
    "                    for pair in tqdm(pool.imap_unordered(_create_single_sequence_pair_for_mp, tasks_args), \n",
    "                                     total=num_total_sequences, \n",
    "                                     desc=\"Creating Dataset Sequences (Parallel)\", \n",
    "                                     unit=\"sequence\", \n",
    "                                     leave=False):\n",
    "                        results_list_pairs.append(pair)\n",
    "                \n",
    "                if results_list_pairs: \n",
    "                    raw_input_sequences, raw_target_sequences = zip(*results_list_pairs)\n",
    "                    self.input_sequences = [torch.tensor(s, dtype=torch.long) for s in raw_input_sequences]\n",
    "                    self.target_sequences = [torch.tensor(s, dtype=torch.long) for s in raw_target_sequences]\n",
    "            else:\n",
    "                if actual_init_workers > 0 : \n",
    "                    print(f\"Dataset size ({num_total_sequences} sequences) or worker load too small for parallel init with {actual_init_workers} workers. Using sequential.\")\n",
    "                \n",
    "                for i in tqdm(range(num_total_sequences), desc=\"Creating Dataset Sequences (Sequential)\", unit=\"sequence\", leave=False):\n",
    "                    self.input_sequences.append(torch.tensor(self.indexed_obj_ids[i : i + self.sequence_length], dtype=torch.long))\n",
    "                    self.target_sequences.append(torch.tensor(self.indexed_obj_ids[i + 1 : i + self.sequence_length + 1], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_sequences[idx], self.target_sequences[idx]\n",
    "    \n",
    "    def get_vocab_info(self):\n",
    "        return {'obj_to_idx': self.obj_to_idx, 'idx_to_obj': self.idx_to_obj, 'vocab_size': self.vocab_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4fc02-fb50-439e-9bdf-a5ee03e6a9b3",
   "metadata": {},
   "source": [
    "# 4. Define Training and Evaluation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25ff348-9c8f-4a3f-97b7-7a7939719a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.Module, \n",
    "                optimizer: optim.Optimizer, device: torch.device, grad_clip_value: float = None, epoch_num: int = 0, config_name: str = \"\"):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    batch_iterator = tqdm(dataloader, desc=f\"Epoch {epoch_num} Training\", leave=False, unit=\"batch\")\n",
    "    for batch_idx, (input_seqs, target_seqs) in enumerate(batch_iterator):\n",
    "        input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_seqs, src_key_padding_mask=None)\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), target_seqs.view(-1))\n",
    "        loss.backward()\n",
    "        if grad_clip_value:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        batch_iterator.set_postfix_str(f\"Loss: {loss.item():.4f}\")\n",
    "    return total_loss / len(dataloader) if len(dataloader) > 0 else 0.0\n",
    "\n",
    "'''\n",
    "Evaluasi digunakan mensimulasikan performa LRU cache dengan prefetcher\n",
    "Prefetcher yang digunakan hanya melakukan prefetching terhadap satu objek saja\n",
    "'''\n",
    "def evaluate_model_with_prefetcher(model: nn.Module, dataloader: DataLoader, criterion: nn.Module, \n",
    "                                   device: torch.device, model_vocab_size: int, \n",
    "                                   k_items_to_prefetch: int = 1, \n",
    "                                   cache_size_percentage: float = 0.1):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_lru_misses = 0\n",
    "    total_lru_accesses = 0\n",
    "    \n",
    "    if model_vocab_size == 0:\n",
    "        print(\"Warning: model_vocab_size is 0. LRU simulation might not be meaningful.\")\n",
    "        cache_capacity = k_items_to_prefetch \n",
    "    else:\n",
    "        cache_capacity = max(1, int(model_vocab_size * cache_size_percentage))\n",
    "    \n",
    "    lru_cache = deque(maxlen=cache_capacity)\n",
    "\n",
    "    batch_iterator = tqdm(dataloader, desc=\"Evaluating with Prefetcher+LRU\", leave=False, unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for input_seqs, target_seqs in batch_iterator: \n",
    "            input_seqs, target_seqs = input_seqs.to(device), target_seqs.to(device)\n",
    "            outputs = model(input_seqs, src_key_padding_mask=None) \n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), target_seqs.view(-1))\n",
    "            total_loss += loss.item() \n",
    "\n",
    "            for b in range(input_seqs.size(0)): \n",
    "                for s in range(target_seqs.size(1)): \n",
    "                    current_logits_for_prefetch = outputs[b, s, :]\n",
    "                    actual_demanded_item_idx = target_seqs[b, s].item()\n",
    "\n",
    "                    if k_items_to_prefetch > 0:\n",
    "                        _, predicted_indices_to_prefetch = torch.topk(\n",
    "                            current_logits_for_prefetch, \n",
    "                            k=min(k_items_to_prefetch, model_vocab_size if model_vocab_size > 0 else k_items_to_prefetch), \n",
    "                            dim=-1\n",
    "                        )\n",
    "                        for pred_idx_tensor in predicted_indices_to_prefetch:\n",
    "                            pred_idx = pred_idx_tensor.item()\n",
    "                            if pred_idx in lru_cache:\n",
    "                                lru_cache.remove(pred_idx) \n",
    "                            lru_cache.append(pred_idx) \n",
    "                    \n",
    "                    total_lru_accesses += 1\n",
    "                    if actual_demanded_item_idx in lru_cache:\n",
    "                        lru_cache.remove(actual_demanded_item_idx) \n",
    "                        lru_cache.append(actual_demanded_item_idx)\n",
    "                    else:\n",
    "                        total_lru_misses += 1\n",
    "                        if actual_demanded_item_idx in lru_cache: \n",
    "                            lru_cache.remove(actual_demanded_item_idx)\n",
    "                        lru_cache.append(actual_demanded_item_idx)\n",
    "            \n",
    "    avg_loss_per_batch = total_loss / len(dataloader) if len(dataloader) > 0 else 0.0\n",
    "    lru_miss_ratio = total_lru_misses / total_lru_accesses if total_lru_accesses > 0 else 0.0\n",
    "    return avg_loss_per_batch, lru_miss_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8800ab8-f494-44bd-b8a3-f3e3ce69bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Bagian ini akan mengevaluasi performa cache LRU tanpa prefetcher sebagai baseline\n",
    "'''\n",
    "def evaluate_lru_only_cache(dataloader: DataLoader, device: torch.device, \n",
    "                            model_vocab_size: int, cache_size_percentage: float = 0.1):\n",
    "    total_lru_misses = 0\n",
    "    total_lru_accesses = 0\n",
    "\n",
    "    if model_vocab_size == 0:\n",
    "        print(\"Warning: model_vocab_size is 0 for LRU-only. Cache capacity might be 0.\")\n",
    "        cache_capacity = 1\n",
    "    else:\n",
    "        cache_capacity = max(1, int(model_vocab_size * cache_size_percentage))\n",
    "    \n",
    "    print(f\"Simulating Baseline LRU cache with capacity: {cache_capacity} ({cache_size_percentage*100:.1f}% of vocab {model_vocab_size}).\")\n",
    "    \n",
    "    lru_cache = deque(maxlen=cache_capacity)\n",
    "\n",
    "    batch_iterator = tqdm(dataloader, desc=\"Evaluating Baseline LRU\", leave=False, unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for _, target_seqs in batch_iterator:\n",
    "            target_seqs = target_seqs.to(device)\n",
    "\n",
    "            for b in range(target_seqs.size(0)):\n",
    "                for s in range(target_seqs.size(1)):\n",
    "                    actual_demanded_item_idx = target_seqs[b, s].item()\n",
    "                    \n",
    "                    total_lru_accesses += 1\n",
    "\n",
    "                    if actual_demanded_item_idx in lru_cache:\n",
    "                        # Cache Hit\n",
    "                        lru_cache.remove(actual_demanded_item_idx)\n",
    "                        lru_cache.append(actual_demanded_item_idx)\n",
    "                    else:\n",
    "                        total_lru_misses += 1\n",
    "                        if actual_demanded_item_idx in lru_cache:\n",
    "                            lru_cache.remove(actual_demanded_item_idx)\n",
    "                        lru_cache.append(actual_demanded_item_idx)\n",
    "            \n",
    "    lru_miss_ratio = total_lru_misses / total_lru_accesses if total_lru_accesses > 0 else 0.0\n",
    "    return lru_miss_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366803d-31cd-4fc4-bd1c-c201844d2e68",
   "metadata": {},
   "source": [
    "# 5. Load Processed Data and Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b531771-8b83-40d4-a856-86cb73937c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data from processed_cache_data.pkl...\n",
      "Loaded filtered sequence of length: 15000\n",
      "Number of unique popular objects for vocabulary: 7588\n",
      "Training sequence length: 12000\n",
      "Validation sequence length: 3000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading processed data from {PROCESSED_DATA_PICKLE_PATH}...\")\n",
    "if not os.path.exists(PROCESSED_DATA_PICKLE_PATH):\n",
    "    print(f\"Error: Processed data file not found at {PROCESSED_DATA_PICKLE_PATH}.\")\n",
    "    print(\"Please run the preprocessing notebook first to generate this file.\")\n",
    "    raise FileNotFoundError(f\"Missing {PROCESSED_DATA_PICKLE_PATH}\")\n",
    "\n",
    "with open(PROCESSED_DATA_PICKLE_PATH, 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "filtered_sequence = processed_data['filtered_sequence_popular_obj_ids']\n",
    "list_of_popular_objects_for_vocab = processed_data['list_of_popular_obj_ids']\n",
    "\n",
    "print(f\"Loaded filtered sequence of length: {len(filtered_sequence)}\")\n",
    "print(f\"Number of unique popular objects for vocabulary: {len(list_of_popular_objects_for_vocab)}\")\n",
    "\n",
    "if not filtered_sequence or not list_of_popular_objects_for_vocab:\n",
    "    print(\"Error: Loaded data is empty. Cannot proceed with training.\")\n",
    "    raise ValueError(\"Empty data loaded from pickle file.\")\n",
    "\n",
    "# Split the filtered sequence for training and validation\n",
    "split_idx = int(TRAIN_SPLIT_RATIO * len(filtered_sequence))\n",
    "train_filtered_ids = filtered_sequence[:split_idx]\n",
    "val_filtered_ids = filtered_sequence[split_idx:]\n",
    "\n",
    "print(f\"Training sequence length: {len(train_filtered_ids)}\")\n",
    "print(f\"Validation sequence length: {len(val_filtered_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d273d8-a8aa-400c-8c01-0a4477128003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Training Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ea0813acf843fea01476aef4242c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Dataset Sequences (Sequential):   0%|          | 0/11980 [00:00<?, ?sequence/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Validation Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738e246d15f14c81927ede20fade45c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Dataset Sequences (Sequential):   0%|          | 0/2980 [00:00<?, ?sequence/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Creating Training Dataset...\")\n",
    "train_dataset = CacheDataset(train_filtered_ids, list_of_popular_objects_for_vocab, SEQ_LENGTH, num_init_workers=NUM_INIT_WORKERS_DATASET)\n",
    "print(\"Creating Validation Dataset...\")\n",
    "val_dataset = CacheDataset(val_filtered_ids, list_of_popular_objects_for_vocab, SEQ_LENGTH, num_init_workers=NUM_INIT_WORKERS_DATASET)\n",
    "\n",
    "if len(train_dataset) == 0:\n",
    "    raise ValueError(\"Training dataset is empty after processing. Insufficient data for SEQ_LENGTH.\")\n",
    "if len(val_dataset) == 0:\n",
    "    print(\"Warning: Validation dataset is empty. Evaluation will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ee97cd-8f69-40a7-b336-a9ae0625057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory_flag = True if device.type == 'cuda' else False\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=NUM_WORKERS_DATALOADER, pin_memory=pin_memory_flag)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS_DATALOADER, pin_memory=pin_memory_flag) if len(val_dataset) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4827c86-971c-4926-8181-8dc03b4bb104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective Vocabulary size for all models: 7588\n",
      "Number of training sequences: 11980\n",
      "Number of validation sequences: 2980\n"
     ]
    }
   ],
   "source": [
    "MODEL_VOCAB_SIZE = train_dataset.vocab_size\n",
    "print(f\"Effective Vocabulary size for all models: {MODEL_VOCAB_SIZE}\")\n",
    "print(f\"Number of training sequences: {len(train_dataset)}\")\n",
    "print(f\"Number of validation sequences: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f449728-86e1-457d-8456-67626cc914e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating Baseline LRU cache with capacity: 7 (0.1% of vocab 7588).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10b3128890f4d549f6bd1af4bd6e52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Baseline LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline LRU-Only Cache Miss Ratio (on validation set): 0.7043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_lru_miss_ratio = float('nan')\n",
    "if val_dataloader and len(val_dataset) > 0:\n",
    "    if MODEL_VOCAB_SIZE > 0:\n",
    "        baseline_lru_miss_ratio = evaluate_lru_only_cache(\n",
    "            val_dataloader, device, \n",
    "            model_vocab_size=MODEL_VOCAB_SIZE, \n",
    "            cache_size_percentage=LRU_CACHE_SIZE_PERCENTAGE\n",
    "        )\n",
    "        print(f\"\\nBaseline LRU-Only Cache Miss Ratio (on validation set): {baseline_lru_miss_ratio:.4f}\\n\")\n",
    "    else:\n",
    "        print(\"\\nMODEL_VOCAB_SIZE is 0, cannot run baseline LRU-only cache evaluation meaningfully.\")\n",
    "else:\n",
    "    print(\"\\nValidation dataloader not available, skipping baseline LRU-only cache evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca48cb-8824-4cad-85ac-c9d51f77d1de",
   "metadata": {},
   "source": [
    "# 6. Define Hyperparameter Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4623ebac-ca76-4838-85e0-584b0e4889c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_configs = [\n",
    "    {\n",
    "        \"name\": \"Config1_MQA_Baseline\", # Renamed to reflect MQA\n",
    "        \"D_MODEL\": 128,\n",
    "        \"NUM_QUERY_HEADS\": 4, # Number of heads for Query in MQA\n",
    "        \"NUM_LAYERS\": 3,\n",
    "        \"D_FF\": 256,\n",
    "        \"DROPOUT\": 0.1,\n",
    "        \"LEARNING_RATE\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config2_MQA_LargerModel_LowerLR\",\n",
    "        \"D_MODEL\": 256, \n",
    "        \"NUM_QUERY_HEADS\": 8,  \n",
    "        \"NUM_LAYERS\": 4, \n",
    "        \"D_FF\": 512,   \n",
    "        \"DROPOUT\": 0.15, \n",
    "        \"LEARNING_RATE\": 0.0005, \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config3_MQA_SmallerModel_HigherLR_MoreDropout\",\n",
    "        \"D_MODEL\": 64,  \n",
    "        \"NUM_QUERY_HEADS\": 2,  \n",
    "        \"NUM_LAYERS\": 2, \n",
    "        \"D_FF\": 128,   \n",
    "        \"DROPOUT\": 0.2,  \n",
    "        \"LEARNING_RATE\": 0.002, \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config4_MQA_MediumModel_MoreQueryHeads\",\n",
    "        \"D_MODEL\": 128,\n",
    "        \"NUM_QUERY_HEADS\": 8, # More query heads for same D_MODEL\n",
    "        \"NUM_LAYERS\": 3,\n",
    "        \"D_FF\": 256,\n",
    "        \"DROPOUT\": 0.1,\n",
    "        \"LEARNING_RATE\": 0.001,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598b3ad-439a-4dcc-9bd3-be1343661da7",
   "metadata": {},
   "source": [
    "# 7. Training and Evaluation Loop for Each Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8293db-6339-4732-be67-87dcb8b6f641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0b78df99d460ca670841beb9d9342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Configurations:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================== Starting Training for: Config1_MQA_Baseline ====================\n",
      "Hyperparameters: {'name': 'Config1_MQA_Baseline', 'D_MODEL': 128, 'NUM_QUERY_HEADS': 4, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "Model for Config1_MQA_Baseline initialized with 2273508 trainable parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f470de318e7a4032b0d6b94d8887720d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config1_MQA_Baseline' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae7d1a3928f422f927e0d834af8a80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 1 Training: Avg Model Loss: 2.8702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f97207e7104f218978ca476cb64289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 1 Validation: Avg Model Loss: 12.3316, Prefetcher+LRU Miss Ratio: 0.6894\n",
      "Config: Config1_MQA_Baseline, Epoch 1 duration: 77.70 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f63365ba5a2474693f4b8609f2d84d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 2 Training: Avg Model Loss: 0.5214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3098ef429924428b9c7db893c6852ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 2 Validation: Avg Model Loss: 13.8054, Prefetcher+LRU Miss Ratio: 0.6951\n",
      "Config: Config1_MQA_Baseline, Epoch 2 duration: 79.00 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16c2e553c064a0693a7eb0b1b92f24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 3 Training: Avg Model Loss: 0.4025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5add3c5109ec47879b62a358e5ecdd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 3 Validation: Avg Model Loss: 14.2197, Prefetcher+LRU Miss Ratio: 0.6964\n",
      "Config: Config1_MQA_Baseline, Epoch 3 duration: 78.14 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b28283a9c443b8b0f68cb16712c40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 4 Training: Avg Model Loss: 0.3610\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb020ed66bd4cad838ee3318a4affbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 4 Validation: Avg Model Loss: 14.4871, Prefetcher+LRU Miss Ratio: 0.6950\n",
      "Config: Config1_MQA_Baseline, Epoch 4 duration: 75.89 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a365b46b0d4cc2af693acb438f20eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 5 Training: Avg Model Loss: 0.3312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5bb496efcf4e0687777899589aa382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config1_MQA_Baseline, Epoch 5 Validation: Avg Model Loss: 15.1268, Prefetcher+LRU Miss Ratio: 0.6895\n",
      "Config: Config1_MQA_Baseline, Epoch 5 duration: 79.36 seconds\n",
      "\n",
      "Training for Config1_MQA_Baseline completed in 390.24 seconds.\n",
      "Best Validation Prefetcher+LRU Miss Ratio for Config1_MQA_Baseline: 0.6894 at Epoch 1\n",
      "\n",
      "\n",
      "==================== Starting Training for: Config2_MQA_LargerModel_LowerLR ====================\n",
      "Hyperparameters: {'name': 'Config2_MQA_LargerModel_LowerLR', 'D_MODEL': 256, 'NUM_QUERY_HEADS': 8, 'NUM_LAYERS': 4, 'D_FF': 512, 'DROPOUT': 0.15, 'LEARNING_RATE': 0.0005}\n",
      "Model for Config2_MQA_LargerModel_LowerLR initialized with 5541028 trainable parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb318618dba457cab94b6a29c7ad10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config2_MQA_LargerModel_LowerLR' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7ad04771394d4bb7567927d07864af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 1 Training: Avg Model Loss: 3.0454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7b5084aad144798eaa3fb742ee5d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 1 Validation: Avg Model Loss: 11.5336, Prefetcher+LRU Miss Ratio: 0.6908\n",
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 1 duration: 87.60 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbe9c5546ec4268b036de92433c248e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 2 Training: Avg Model Loss: 0.5527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455a75395e2c4250bd4f0a69de35dec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 2 Validation: Avg Model Loss: 13.6804, Prefetcher+LRU Miss Ratio: 0.6844\n",
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 2 duration: 87.43 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bf30f5ea76423abad08c5423b68c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 3 Training: Avg Model Loss: 0.3921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea821d6cc2a3493396329a233f7bd008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 3 Validation: Avg Model Loss: 14.5103, Prefetcher+LRU Miss Ratio: 0.6848\n",
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 3 duration: 87.55 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e730d5d5354cd8a039ef6ba627cc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 4 Training: Avg Model Loss: 0.3452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673e958a83c946d8b8fad748f93eee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 4 Validation: Avg Model Loss: 14.7940, Prefetcher+LRU Miss Ratio: 0.6863\n",
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 4 duration: 87.73 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183604f880db4d48a5ecc4424152b3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 5 Training: Avg Model Loss: 0.3200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e31f3d65b24bb1a7c58865f0887301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 5 Validation: Avg Model Loss: 14.9909, Prefetcher+LRU Miss Ratio: 0.6883\n",
      "Config: Config2_MQA_LargerModel_LowerLR, Epoch 5 duration: 87.52 seconds\n",
      "\n",
      "Training for Config2_MQA_LargerModel_LowerLR completed in 438.13 seconds.\n",
      "Best Validation Prefetcher+LRU Miss Ratio for Config2_MQA_LargerModel_LowerLR: 0.6844 at Epoch 2\n",
      "\n",
      "\n",
      "==================== Starting Training for: Config3_MQA_SmallerModel_HigherLR_MoreDropout ====================\n",
      "Hyperparameters: {'name': 'Config3_MQA_SmallerModel_HigherLR_MoreDropout', 'D_MODEL': 64, 'NUM_QUERY_HEADS': 2, 'NUM_LAYERS': 2, 'D_FF': 128, 'DROPOUT': 0.2, 'LEARNING_RATE': 0.002}\n",
      "Model for Config3_MQA_SmallerModel_HigherLR_MoreDropout initialized with 1037604 trainable parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e42451c16f49bc813d013f49d40689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config3_MQA_SmallerModel_HigherLR_MoreDropout' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d60ca0364bd45deae031fd436e05af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 1 Training: Avg Model Loss: 3.7167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233219e766d3482a8f6476fc8b1824d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 1 Validation: Avg Model Loss: 15.1157, Prefetcher+LRU Miss Ratio: 0.6867\n",
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 1 duration: 65.28 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abb524c37024fd5b95e718255cc8e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 2 Training: Avg Model Loss: 1.1389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c40faf476749d0adf340ca04561552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 2 Validation: Avg Model Loss: 17.0227, Prefetcher+LRU Miss Ratio: 0.6871\n",
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 2 duration: 65.52 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a0cfbe4cae4d7fa2a036d162ef30f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 3 Training: Avg Model Loss: 0.8006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e52a8497c24258984bb56467697777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 3 Validation: Avg Model Loss: 18.0005, Prefetcher+LRU Miss Ratio: 0.6859\n",
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 3 duration: 64.71 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610a7c0b197c48d9bea789f74e21cdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 4 Training: Avg Model Loss: 0.6973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dfdea1fb8d4a258d33e0b97efe5e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 4 Validation: Avg Model Loss: 18.7145, Prefetcher+LRU Miss Ratio: 0.6849\n",
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 4 duration: 47.65 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7020b8acd04e8596c541fc95d6cbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 5 Training: Avg Model Loss: 0.6395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082a11d432bf44a39bf48eb65a4a7282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 5 Validation: Avg Model Loss: 18.8699, Prefetcher+LRU Miss Ratio: 0.6900\n",
      "Config: Config3_MQA_SmallerModel_HigherLR_MoreDropout, Epoch 5 duration: 64.83 seconds\n",
      "\n",
      "Training for Config3_MQA_SmallerModel_HigherLR_MoreDropout completed in 308.10 seconds.\n",
      "Best Validation Prefetcher+LRU Miss Ratio for Config3_MQA_SmallerModel_HigherLR_MoreDropout: 0.6849 at Epoch 4\n",
      "\n",
      "\n",
      "==================== Starting Training for: Config4_MQA_MediumModel_MoreQueryHeads ====================\n",
      "Hyperparameters: {'name': 'Config4_MQA_MediumModel_MoreQueryHeads', 'D_MODEL': 128, 'NUM_QUERY_HEADS': 8, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "Model for Config4_MQA_MediumModel_MoreQueryHeads initialized with 2261124 trainable parameters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9d7d5e6b0742378ce041d0c73139d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Config 'Config4_MQA_MediumModel_MoreQueryHeads' Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d672f82812451c8010cb4be779943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 1 Training: Avg Model Loss: 2.9206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e490eadbaf584cd59dfd2204bcdf476f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 1 Validation: Avg Model Loss: 12.1083, Prefetcher+LRU Miss Ratio: 0.6914\n",
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 1 duration: 78.48 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82b1d08710e495f8414408c22b92ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 2 Training: Avg Model Loss: 0.5414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7432ca8d774c34bb2506904de889ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 2 Validation: Avg Model Loss: 14.3730, Prefetcher+LRU Miss Ratio: 0.6880\n",
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 2 duration: 68.99 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e948dda07a6d44b49f7ad6964344b891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 3 Training: Avg Model Loss: 0.4090\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a813d4750443f39b5bef7b41559147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 3 Validation: Avg Model Loss: 15.1056, Prefetcher+LRU Miss Ratio: 0.6869\n",
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 3 duration: 79.12 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225a44ac9e1043ec893cc97eff6269ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 4 Training: Avg Model Loss: 0.3627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb50623cd1e428796718c867ce978c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 4 Validation: Avg Model Loss: 15.4308, Prefetcher+LRU Miss Ratio: 0.6888\n",
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 4 duration: 80.03 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5e59455e17484dbb8d3064e0958c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/1497 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 5 Training: Avg Model Loss: 0.3375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5e4451ea1c49c7826b492f68d6350e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating with Prefetcher+LRU:   0%|          | 0/373 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 5 Validation: Avg Model Loss: 14.9194, Prefetcher+LRU Miss Ratio: 0.7044\n",
      "Config: Config4_MQA_MediumModel_MoreQueryHeads, Epoch 5 duration: 78.16 seconds\n",
      "\n",
      "Training for Config4_MQA_MediumModel_MoreQueryHeads completed in 384.95 seconds.\n",
      "Best Validation Prefetcher+LRU Miss Ratio for Config4_MQA_MediumModel_MoreQueryHeads: 0.6869 at Epoch 3\n",
      "\n",
      "\n",
      "==================== All Configurations Processed ====================\n"
     ]
    }
   ],
   "source": [
    "all_results = [] \n",
    "\n",
    "configurations_pbar = tqdm(hyperparameter_configs, desc=\"Configurations\")\n",
    "for config in configurations_pbar: \n",
    "    print(f\"\\n\\n{'='*20} Starting Training for: {config['name']} {'='*20}\")\n",
    "    print(f\"Hyperparameters: {config}\")\n",
    "    start_time_config = time.time()\n",
    "\n",
    "    current_model = DecoderOnlyTransformerScratch(\n",
    "        vocab_size=MODEL_VOCAB_SIZE,\n",
    "        d_model=config['D_MODEL'],\n",
    "        num_query_heads=config['NUM_QUERY_HEADS'], # Use NUM_QUERY_HEADS\n",
    "        num_layers=config['NUM_LAYERS'],\n",
    "        d_ff=config['D_FF'],\n",
    "        max_seq_length=MODEL_MAX_SEQ_LENGTH,\n",
    "        dropout=config['DROPOUT']\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = optim.Adam(current_model.parameters(), lr=config['LEARNING_RATE'])\n",
    "\n",
    "    num_params = sum(p.numel() for p in current_model.parameters() if p.requires_grad)\n",
    "    print(f\"Model for {config['name']} initialized with {num_params} trainable parameters.\")\n",
    "\n",
    "    config_results = {\n",
    "        \"config_name\": config['name'],\n",
    "        \"hyperparameters\": config,\n",
    "        \"num_parameters\": num_params,\n",
    "        \"train_losses\": [],\n",
    "        \"val_model_losses\": [], \n",
    "        \"val_lru_miss_ratios_with_prefetcher\": [], \n",
    "        \"best_val_lru_miss_ratio_with_prefetcher\": float('inf'), \n",
    "        \"best_epoch\": -1\n",
    "    }\n",
    "\n",
    "    if len(train_dataloader) == 0:\n",
    "        print(f\"Training dataloader is empty for {config['name']}. Skipping training for this config.\")\n",
    "        all_results.append(config_results) \n",
    "        continue\n",
    "\n",
    "    for epoch in tqdm(range(1, NUM_EPOCHS + 1), desc=f\"Config '{config['name']}' Epochs\", leave=False):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        avg_train_loss = train_epoch(current_model, train_dataloader, criterion, optimizer, device, GRAD_CLIP, epoch_num=epoch, config_name=config['name'])\n",
    "        config_results[\"train_losses\"].append(avg_train_loss)\n",
    "        print(f\"Config: {config['name']}, Epoch {epoch} Training: Avg Model Loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        current_val_model_loss = float('nan')\n",
    "        current_val_lru_miss_ratio_with_prefetcher = float('nan')\n",
    "\n",
    "        if val_dataloader and len(val_dataset) > 0:\n",
    "            avg_val_model_loss, val_lru_miss_ratio_wp = evaluate_model_with_prefetcher( \n",
    "                current_model, val_dataloader, criterion, device, \n",
    "                model_vocab_size=MODEL_VOCAB_SIZE, \n",
    "                k_items_to_prefetch=K_PREFETCH_MODEL, \n",
    "                cache_size_percentage=LRU_CACHE_SIZE_PERCENTAGE\n",
    "            )\n",
    "            config_results[\"val_model_losses\"].append(avg_val_model_loss)\n",
    "            config_results[\"val_lru_miss_ratios_with_prefetcher\"].append(val_lru_miss_ratio_wp)\n",
    "            current_val_model_loss = avg_val_model_loss\n",
    "            current_val_lru_miss_ratio_with_prefetcher = val_lru_miss_ratio_wp\n",
    "            print(f\"Config: {config['name']}, Epoch {epoch} Validation: Avg Model Loss: {avg_val_model_loss:.4f}, Prefetcher+LRU Miss Ratio: {val_lru_miss_ratio_wp:.4f}\")\n",
    "            \n",
    "            if not math.isnan(val_lru_miss_ratio_wp) and val_lru_miss_ratio_wp < config_results[\"best_val_lru_miss_ratio_with_prefetcher\"]:\n",
    "                config_results[\"best_val_lru_miss_ratio_with_prefetcher\"] = val_lru_miss_ratio_wp\n",
    "                config_results[\"best_epoch\"] = epoch\n",
    "        else:\n",
    "            config_results[\"val_model_losses\"].append(float('nan')) \n",
    "            config_results[\"val_lru_miss_ratios_with_prefetcher\"].append(float('nan'))\n",
    "            if len(val_dataset) == 0:\n",
    "                 print(f\"Config: {config['name']}, Epoch {epoch}: Validation dataset is empty. Skipping validation.\")\n",
    "            else:\n",
    "                 print(f\"Config: {config['name']}, Epoch {epoch}: Validation dataloader not available. Skipping validation.\")\n",
    "        \n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        if not math.isnan(current_val_lru_miss_ratio_with_prefetcher):\n",
    "             configurations_pbar.set_description_str(f\"Cfgs (Best P+LRUMR for {config['name']}: {config_results['best_val_lru_miss_ratio_with_prefetcher']:.4f})\")\n",
    "        print(f\"Config: {config['name']}, Epoch {epoch} duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "    config_duration = time.time() - start_time_config\n",
    "    print(f\"\\nTraining for {config['name']} completed in {config_duration:.2f} seconds.\")\n",
    "    print(f\"Best Validation Prefetcher+LRU Miss Ratio for {config['name']}: {config_results['best_val_lru_miss_ratio_with_prefetcher']:.4f} at Epoch {config_results['best_epoch']}\")\n",
    "    all_results.append(config_results)\n",
    "    configurations_pbar.set_description_str(\"Configurations\") \n",
    "\n",
    "print(f\"\\n\\n{'='*20} All Configurations Processed {'='*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4114f2f-c5d2-43bc-81e9-78a0e2ae8453",
   "metadata": {},
   "source": [
    "# 8. Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1902af19-b265-4d36-948a-02c917528ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration: Config1_MQA_Baseline\n",
      "  Hyperparameters: {'name': 'Config1_MQA_Baseline', 'D_MODEL': 128, 'NUM_QUERY_HEADS': 4, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "  Trainable Parameters: 2273508\n",
      "  Final Training Model Loss (Epoch 5): 0.3312\n",
      "  Final Validation Model Loss (Epoch 5): 15.1268\n",
      "  Final Validation Prefetcher+LRU Miss Ratio: 0.6895\n",
      "  Best Validation Prefetcher+LRU Miss Ratio: 0.6894 (Epoch 1)\n",
      "  Improvement over Baseline LRU: 0.0149 (2.11%)\n",
      "\n",
      "Configuration: Config2_MQA_LargerModel_LowerLR\n",
      "  Hyperparameters: {'name': 'Config2_MQA_LargerModel_LowerLR', 'D_MODEL': 256, 'NUM_QUERY_HEADS': 8, 'NUM_LAYERS': 4, 'D_FF': 512, 'DROPOUT': 0.15, 'LEARNING_RATE': 0.0005}\n",
      "  Trainable Parameters: 5541028\n",
      "  Final Training Model Loss (Epoch 5): 0.3200\n",
      "  Final Validation Model Loss (Epoch 5): 14.9909\n",
      "  Final Validation Prefetcher+LRU Miss Ratio: 0.6883\n",
      "  Best Validation Prefetcher+LRU Miss Ratio: 0.6844 (Epoch 2)\n",
      "  Improvement over Baseline LRU: 0.0199 (2.82%)\n",
      "\n",
      "Configuration: Config3_MQA_SmallerModel_HigherLR_MoreDropout\n",
      "  Hyperparameters: {'name': 'Config3_MQA_SmallerModel_HigherLR_MoreDropout', 'D_MODEL': 64, 'NUM_QUERY_HEADS': 2, 'NUM_LAYERS': 2, 'D_FF': 128, 'DROPOUT': 0.2, 'LEARNING_RATE': 0.002}\n",
      "  Trainable Parameters: 1037604\n",
      "  Final Training Model Loss (Epoch 5): 0.6395\n",
      "  Final Validation Model Loss (Epoch 5): 18.8699\n",
      "  Final Validation Prefetcher+LRU Miss Ratio: 0.6900\n",
      "  Best Validation Prefetcher+LRU Miss Ratio: 0.6849 (Epoch 4)\n",
      "  Improvement over Baseline LRU: 0.0194 (2.75%)\n",
      "\n",
      "Configuration: Config4_MQA_MediumModel_MoreQueryHeads\n",
      "  Hyperparameters: {'name': 'Config4_MQA_MediumModel_MoreQueryHeads', 'D_MODEL': 128, 'NUM_QUERY_HEADS': 8, 'NUM_LAYERS': 3, 'D_FF': 256, 'DROPOUT': 0.1, 'LEARNING_RATE': 0.001}\n",
      "  Trainable Parameters: 2261124\n",
      "  Final Training Model Loss (Epoch 5): 0.3375\n",
      "  Final Validation Model Loss (Epoch 5): 14.9194\n",
      "  Final Validation Prefetcher+LRU Miss Ratio: 0.7044\n",
      "  Best Validation Prefetcher+LRU Miss Ratio: 0.6869 (Epoch 3)\n",
      "  Improvement over Baseline LRU: 0.0174 (2.47%)\n"
     ]
    }
   ],
   "source": [
    "for result in all_results:\n",
    "    print(f\"\\nConfiguration: {result['config_name']}\")\n",
    "    print(f\"  Hyperparameters: {result['hyperparameters']}\")\n",
    "    print(f\"  Trainable Parameters: {result['num_parameters']}\")\n",
    "    if result['train_losses']: \n",
    "        print(f\"  Final Training Model Loss (Epoch {len(result['train_losses'])}): {result['train_losses'][-1]:.4f}\")\n",
    "        if result['val_lru_miss_ratios_with_prefetcher'] and not math.isnan(result['val_lru_miss_ratios_with_prefetcher'][-1]):\n",
    "             print(f\"  Final Validation Model Loss (Epoch {len(result['val_model_losses'])}): {result['val_model_losses'][-1]:.4f}\")\n",
    "             print(f\"  Final Validation Prefetcher+LRU Miss Ratio: {result['val_lru_miss_ratios_with_prefetcher'][-1]:.4f}\")\n",
    "        print(f\"  Best Validation Prefetcher+LRU Miss Ratio: {result['best_val_lru_miss_ratio_with_prefetcher']:.4f} (Epoch {result['best_epoch']})\")\n",
    "        if not math.isnan(baseline_lru_miss_ratio) and not math.isnan(result['best_val_lru_miss_ratio_with_prefetcher']):\n",
    "            improvement = baseline_lru_miss_ratio - result['best_val_lru_miss_ratio_with_prefetcher']\n",
    "            improvement_percent = (improvement / baseline_lru_miss_ratio) * 100 if baseline_lru_miss_ratio > 0 else 0 # Avoid division by zero\n",
    "            print(f\"  Improvement over Baseline LRU: {improvement:.4f} ({improvement_percent:.2f}%)\")\n",
    "    else:\n",
    "        print(\"  Training was not run for this configuration (e.g., empty dataloader).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b8e4f7-b25d-4f5b-b461-680b94e7ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Overall Best Configuration (based on Prefetcher+LRU Miss Ratio) ---\n",
      "Name: Config2_MQA_LargerModel_LowerLR\n",
      "Best Validation Prefetcher+LRU Miss Ratio: 0.6844 at Epoch 2\n",
      "Hyperparameters: {'name': 'Config2_MQA_LargerModel_LowerLR', 'D_MODEL': 256, 'NUM_QUERY_HEADS': 8, 'NUM_LAYERS': 4, 'D_FF': 512, 'DROPOUT': 0.15, 'LEARNING_RATE': 0.0005}\n",
      "Trainable Parameters: 5541028\n",
      "  Improvement over Baseline LRU: 0.0199 (2.82%)\n"
     ]
    }
   ],
   "source": [
    "best_overall_config_result = None\n",
    "if all_results:\n",
    "    valid_results = [r for r in all_results if r['best_val_lru_miss_ratio_with_prefetcher'] != float('inf') and \\\n",
    "                     r['best_val_lru_miss_ratio_with_prefetcher'] is not None and \\\n",
    "                     not math.isnan(r['best_val_lru_miss_ratio_with_prefetcher'])]\n",
    "    if valid_results:\n",
    "        best_overall_config_result = min(valid_results, key=lambda x: x['best_val_lru_miss_ratio_with_prefetcher'])\n",
    "\n",
    "if best_overall_config_result:\n",
    "    print(f\"\\n--- Overall Best Configuration (based on Prefetcher+LRU Miss Ratio) ---\")\n",
    "    print(f\"Name: {best_overall_config_result['config_name']}\")\n",
    "    print(f\"Best Validation Prefetcher+LRU Miss Ratio: {best_overall_config_result['best_val_lru_miss_ratio_with_prefetcher']:.4f} at Epoch {best_overall_config_result['best_epoch']}\")\n",
    "    print(f\"Hyperparameters: {best_overall_config_result['hyperparameters']}\")\n",
    "    print(f\"Trainable Parameters: {best_overall_config_result['num_parameters']}\")\n",
    "    if not math.isnan(baseline_lru_miss_ratio):\n",
    "        improvement = baseline_lru_miss_ratio - best_overall_config_result['best_val_lru_miss_ratio_with_prefetcher']\n",
    "        improvement_percent = (improvement / baseline_lru_miss_ratio) * 100 if baseline_lru_miss_ratio > 0 else 0\n",
    "        print(f\"  Improvement over Baseline LRU: {improvement:.4f} ({improvement_percent:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\nCould not determine an overall best configuration (e.g., no valid validation results).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
